{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "50bd77d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../GraphStructureLearning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "9bb64fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "import yaml\n",
    "from easydict import EasyDict as edict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "133b42eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from torch_geometric.utils.random import erdos_renyi_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "71093f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import build_fully_connected_edge_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "2cb1a7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = glob('./config/GTS/CCN_Project/test.yaml')[0]\n",
    "config = edict(yaml.load(open(config_file, 'r'), Loader=yaml.FullLoader))\n",
    "dataset_conf = config.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "b64d9c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pickle.load(open('./data/CCN/monkeydata.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "0f6b9de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.reshape(-1, 101, 742).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "04a965c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "d6fa76ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler_x = StandardScaler()\n",
    "# scaler_y = StandardScaler()\n",
    "# scaler_z = StandardScaler()\n",
    "\n",
    "# scaler_x.fit(dataset[:, -3, :])\n",
    "# scaler_y.fit(dataset[:, -2, :])\n",
    "# scaler_z.fit(dataset[:, -1, :])\n",
    "\n",
    "# dataset[:, -3, :] = scaler_x.transform(dataset[:, -3, :])\n",
    "# dataset[:, -2, :] = scaler_y.transform(dataset[:, -2, :])\n",
    "# dataset[:, -1, :] = scaler_z.transform(dataset[:, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "ce7b087f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = dataset[:80, :98, :]\n",
    "train_y = dataset[:80, 98:, :]\n",
    "\n",
    "valid_x = dataset[80:90, :98, :]\n",
    "valid_y = dataset[80:90, 98:, :]\n",
    "\n",
    "test_x = dataset[90:, :98, :]\n",
    "test_y = dataset[90:, 98:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "5384cb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = erdos_renyi_graph(config.nodes_num, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "d659cb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(dataset, dataset_conf, edge_index):\n",
    "    x = dataset[0]\n",
    "    y = dataset[1]\n",
    "    \n",
    "    valid_sampling_locations = []\n",
    "    valid_sampling_locations += [\n",
    "        (dataset_conf.window_size + i)\n",
    "        for i in range(dataset_conf.total_time_length - dataset_conf.window_size + 1)\n",
    "        if (i % dataset_conf.slide) == 0\n",
    "    ]\n",
    "\n",
    "    data_list = []\n",
    "\n",
    "    for trial in range(len(x)):\n",
    "        spike_data = []\n",
    "        trajectory_data = []\n",
    "        for start_idx in valid_sampling_locations:\n",
    "            spike_inputs = x[trial, :, start_idx - dataset_conf.window_size:start_idx]\n",
    "            target_trajectory = y[trial, :, start_idx - dataset_conf.slide:start_idx]\n",
    "\n",
    "            spike_data.append(spike_inputs)\n",
    "            trajectory_data.append(target_trajectory)\n",
    "\n",
    "        spike_inputs = np.stack(spike_data, axis=1)\n",
    "        target_trajectory = np.stack(trajectory_data, axis=1)\n",
    "\n",
    "        data_item = Data(x=torch.FloatTensor(spike_inputs), edge_index=edge_index, y=torch.FloatTensor(target_trajectory))\n",
    "        data_list.append(data_item)\n",
    "\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "904cd521",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_conf.window_size = 202\n",
    "dataset_conf.slide = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "5178a1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = prepare_dataset([train_x, train_y], dataset_conf, edge_index)\n",
    "valid_dataset = prepare_dataset([valid_x, valid_y], dataset_conf, edge_index)\n",
    "test_dataset = prepare_dataset([test_x, test_y], dataset_conf, edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "1fa16d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "eef55500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric_temporal.nn.recurrent import DCRNN\n",
    "\n",
    "class RecurrentGCN(torch.nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(RecurrentGCN, self).__init__()\n",
    "        self.num_nodes = config.nodes_num\n",
    "        self.nodes_feas = config.node_features\n",
    "\n",
    "        self.kernel_size = config.embedding.kernel_size\n",
    "        self.stride = config.embedding.stride\n",
    "        self.conv1_dim = config.embedding.conv1_dim\n",
    "        self.conv2_dim = config.embedding.conv2_dim\n",
    "\n",
    "        self.embedding_dim = config.embedding.embedding_dim\n",
    "\n",
    "        self.conv1 = torch.nn.Conv1d(self.nodes_feas, self.conv1_dim, self.kernel_size, stride=self.stride)\n",
    "        self.conv2 = torch.nn.Conv1d(self.conv1_dim, self.conv2_dim, self.kernel_size, stride=self.stride)\n",
    "\n",
    "        self.bn1 = torch.nn.BatchNorm1d(self.conv1_dim)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(self.conv2_dim)\n",
    "        \n",
    "        self.recurrent = DCRNN(config.embedding.embedding_dim, 16, 1)\n",
    "        \n",
    "        self.conv3 = torch.nn.Conv1d(1, 1, 16, stride=1)\n",
    "        \n",
    "        self.out_1 = torch.nn.Linear(98, 10)\n",
    "        self.out_2 = torch.nn.Linear(98, 10)\n",
    "        self.out_3 = torch.nn.Linear(98, 10)\n",
    "\n",
    "    def forward(self, x, edge_index, hidden_state):\n",
    "        batch_nodes = x.shape[0]\n",
    "        if len(x.shape) == 2:\n",
    "            inputs = x.reshape(batch_nodes, 1, -1)\n",
    "        x = self.conv1(inputs)\n",
    "        x = F.relu(x)\n",
    "        x = self.bn1(x)\n",
    "#         print(x.shape)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.bn2(x)\n",
    "#         print(x.shape)\n",
    "\n",
    "        x = x.view(batch_nodes, -1) \n",
    "#         print(x.shape)\n",
    "        \n",
    "        \n",
    "        h = self.recurrent(x, edge_index, H=hidden_state)\n",
    "        h = F.relu(h)\n",
    "#         print(h.shape)\n",
    "        \n",
    "        h_ = h.view(batch_nodes, 1, self.embedding_dim)\n",
    "#         print(h_.shape)\n",
    "        forecast_h = self.conv3(h_)\n",
    "        forecast_h = F.relu(forecast_h)\n",
    "#         print(forecast_h.shape)\n",
    "        \n",
    "        forecast_h = forecast_h.view(-1)\n",
    "#         print(forecast_h.shape)\n",
    "        \n",
    "        out_x = self.out_1(forecast_h)\n",
    "        out_y = self.out_2(forecast_h)\n",
    "        out_z = self.out_3(forecast_h)\n",
    "        \n",
    "        \n",
    "        return out_x, out_y, out_z, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "33051466",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/fl/mgh5rhv529ddrf0l95hl_zcm0000gn/T/ipykernel_28713/3469014608.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mcost\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcost\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcost_x\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcost_y\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcost_z\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mcost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/GraphStructureLearning/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/GraphStructureLearning/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "model = RecurrentGCN(config)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in tqdm(range(2)):\n",
    "    for data in train_loader:\n",
    "        H = None\n",
    "        cost = 0\n",
    "        \n",
    "        for time in range(data.x.shape[1]):\n",
    "            cost = 0\n",
    "            out_x, out_y, out_z, H = model(data.x[:, time, :], data.edge_index, H)\n",
    "            \n",
    "            cost_x = torch.mean((out_x-data.y[0,time, :])**2)\n",
    "            cost_y = torch.mean((out_y-data.y[1,time, :])**2)\n",
    "            cost_z = torch.mean((out_z-data.y[2,time, :])**2)\n",
    "        \n",
    "            cost += cost + cost_x + cost_y + cost_z\n",
    "        \n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e127a60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
