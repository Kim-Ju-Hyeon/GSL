{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2719f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dcba8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from easydict import EasyDict as edict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55c86bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = glob('./config/GTS/*.yaml')[0]\n",
    "config = edict(yaml.load(open(config_file, 'r'), Loader=yaml.FullLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13e775b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lambda_raster(im_o, im_t):\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(90, 80))\n",
    "    time = im_o.shape[0] / 10000\n",
    "    extent = [0, time, 0, 100]\n",
    "    im_o = axes[0].imshow(np.transpose(im_o), cmap='binary', extent=extent)\n",
    "    im_t = axes[1].imshow(np.transpose(im_t), cmap='binary', extent=extent)\n",
    "    ylabel = 'Lambda'\n",
    "    axes[0].set_title('Prediction\\n', fontsize = 30)\n",
    "    axes[0].set_xlabel('Time(s)', fontsize = 30)\n",
    "    axes[0].set_ylabel('Node index', fontsize = 30)\n",
    "    axes[0].set_aspect(0.1)\n",
    "    axes[0].tick_params(axis='x', labelsize=20)\n",
    "    axes[0].tick_params(axis='y', labelsize=20)\n",
    "    axes[1].set_title('Target\\n', fontsize = 30)\n",
    "    axes[1].set_xlabel('Time(s)', fontsize = 30)\n",
    "    axes[1].set_ylabel('Node index', fontsize = 30)\n",
    "    axes[1].set_aspect(0.1)\n",
    "    axes[1].tick_params(axis='x', labelsize=20)\n",
    "    axes[1].tick_params(axis='y', labelsize=20)\n",
    "    cax_o = fig.add_axes([axes[0].get_position().x1+0.01,axes[0].get_position().y0,0.02,axes[0].get_position().height])\n",
    "    cax_t = fig.add_axes([axes[1].get_position().x1+0.01,axes[1].get_position().y0,0.02,axes[1].get_position().height])\n",
    "    cbar1 = plt.colorbar(im_o, cax=cax_o)\n",
    "    cbar2 = plt.colorbar(im_t, cax=cax_t)\n",
    "    cbar1.ax.set_ylabel(ylabel, fontsize=30)\n",
    "    cbar1.ax.tick_params(axis='y', labelsize=20)\n",
    "    cbar2.ax.set_ylabel(ylabel, fontsize=30)\n",
    "    cbar2.ax.tick_params(axis='y', labelsize=20)\n",
    "#     plt.savefig(‘./fig/lamall_RNN_{}.png’.format(suffix), bbox_inches=‘tight’)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "020c8617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a131f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike = pickle.load(open('./data/LNP_spk_all.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f644b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995fb8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lam = pickle.load(open('./data/LNP_lam_all.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c818b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lam.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa1b1c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data, Batch, Dataset, InMemoryDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b597fe7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(InMemoryDataset):\n",
    "    def __init__(self, root=None, transform=None, pre_transform=None):\n",
    "        super(Dataset, self).__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "        \n",
    "        self.config = config\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return []\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['train_n100.pt']\n",
    "\n",
    "    \n",
    "    def download(self):\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        lam = pickle.load(open('./data/LNP_lam_all.pickle', 'rb'))\n",
    "        spike = pickle.load(open('./data/LNP_spk_all.pickle', 'rb'))\n",
    "\n",
    "        #[tsteps, neurons] > [neurons, tsteps]\n",
    "        data = spike[:1000]\n",
    "        lam = lam[:1000]\n",
    "\n",
    "        num_neurons = data.shape[0]\n",
    "        total_time = data.shape[-1]\n",
    "        \n",
    "        time_steps = 200 #previous time steps = 20ms\n",
    "        pred_steps = 20 #steps to predict\n",
    "        window_size = time_steps + pred_steps - 1 # for training only\n",
    "        batch_size = int(np.floor(total_time / (window_size + 1)) - 1)\n",
    "\n",
    "        fully_connected = np.ones((num_neurons, num_neurons)) - np.eye(num_neurons)\n",
    "        encoder_edge = np.where(fully_connected)\n",
    "        encoder_edge = np.array([encoder_edge[0], encoder_edge[1]], dtype=np.int64)\n",
    "\n",
    "        data = torch.FloatTensor(data)\n",
    "        lam = torch.FloatTensor(lam)\n",
    "        encoder_edge = torch.LongTensor(encoder_edge)\n",
    "\n",
    "        data_list = []\n",
    "        \n",
    "        for i in tqdm(range(batch_size)):\n",
    "            step = i * (window_size+1)\n",
    "            data_sample = data[:, step:step+window_size]\n",
    "            lam_tar = lam[:, step+time_steps:step+time_steps+pred_steps]\n",
    "            spk_tar = data[:, step+time_steps:step+time_steps+pred_steps]\n",
    "            lam_spk_tar = torch.stack([lam_tar, spk_tar], dim=-1)\n",
    "            data_item = Data(x=data_sample, edge_index=encoder_edge, y=lam_spk_tar)\n",
    "            data_list.append(data_item)\n",
    "\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6741518a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "100%|███████████████████████████████████| 21817/21817 [00:03<00:00, 7021.59it/s]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset('./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64f52681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(21817)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75c46b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
