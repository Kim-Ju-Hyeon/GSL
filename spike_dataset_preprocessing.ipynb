{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2719f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13e775b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lambda_raster(im_o, im_t):\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(90, 80))\n",
    "    time = im_o.shape[0] / 10000\n",
    "    extent = [0, time, 0, 100]\n",
    "    im_o = axes[0].imshow(np.transpose(im_o), cmap='binary', extent=extent)\n",
    "    im_t = axes[1].imshow(np.transpose(im_t), cmap='binary', extent=extent)\n",
    "    ylabel = 'Lambda'\n",
    "    axes[0].set_title('Prediction\\n', fontsize = 30)\n",
    "    axes[0].set_xlabel('Time(s)', fontsize = 30)\n",
    "    axes[0].set_ylabel('Node index', fontsize = 30)\n",
    "    axes[0].set_aspect(0.1)\n",
    "    axes[0].tick_params(axis='x', labelsize=20)\n",
    "    axes[0].tick_params(axis='y', labelsize=20)\n",
    "    axes[1].set_title('Target\\n', fontsize = 30)\n",
    "    axes[1].set_xlabel('Time(s)', fontsize = 30)\n",
    "    axes[1].set_ylabel('Node index', fontsize = 30)\n",
    "    axes[1].set_aspect(0.1)\n",
    "    axes[1].tick_params(axis='x', labelsize=20)\n",
    "    axes[1].tick_params(axis='y', labelsize=20)\n",
    "    cax_o = fig.add_axes([axes[0].get_position().x1+0.01,axes[0].get_position().y0,0.02,axes[0].get_position().height])\n",
    "    cax_t = fig.add_axes([axes[1].get_position().x1+0.01,axes[1].get_position().y0,0.02,axes[1].get_position().height])\n",
    "    cbar1 = plt.colorbar(im_o, cax=cax_o)\n",
    "    cbar2 = plt.colorbar(im_t, cax=cax_t)\n",
    "    cbar1.ax.set_ylabel(ylabel, fontsize=30)\n",
    "    cbar1.ax.tick_params(axis='y', labelsize=20)\n",
    "    cbar2.ax.set_ylabel(ylabel, fontsize=30)\n",
    "    cbar2.ax.tick_params(axis='y', labelsize=20)\n",
    "#     plt.savefig(‘./fig/lamall_RNN_{}.png’.format(suffix), bbox_inches=‘tight’)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "020c8617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a131f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike = pickle.load(open('./data/LNP_spk_all.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7f644b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 4800000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spike.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "995fb8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lam = pickle.load(open('./data/LNP_lam_all.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23c818b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 4800000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lam.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf2dd56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ca79b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69099104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6e2d3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c151efa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spike[:1000].transpose((1,0))\n",
    "lam = lam[:1000].transpose((1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4daa67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neurons = data.shape[0]\n",
    "total_time = data.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9a0b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = 200 #previous time steps = 20ms\n",
    "pred_steps = 20 #steps to predict\n",
    "window_size = time_steps + pred_steps - 1 # for training only\n",
    "batch_size = int(np.floor(total_time / (window_size + 1)) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81960570",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf6bb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7949526e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_connected = np.ones((num_neurons, num_neurons)) - np.eye(num_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219804a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fully_connected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb948e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_edge = np.where(fully_connected)\n",
    "encoder_edge = np.array([encoder_edge[0], encoder_edge[1]], dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb9750c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4898d951",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_edge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add32727",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.FloatTensor(data)\n",
    "lam = torch.FloatTensor(lam)\n",
    "encoder_edge = torch.LongTensor(encoder_edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41edbf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9e81d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "\n",
    "for i in tqdm(range(batch_size)):\n",
    "    step = i * (window_size+1)\n",
    "    data_sample = data[:, step:step+window_size]\n",
    "    lam_tar = lam[:, step+time_steps:step+time_steps+pred_steps]\n",
    "    spk_tar = data[:, step+time_steps:step+time_steps+pred_steps]\n",
    "    lam_spk_tar = torch.stack([lam_tar, spk_tar], dim=-1)\n",
    "    data_item = Data(x=data_sample, edge_index=encoder_edge, y=lam_spk_tar)\n",
    "    data_list.append(data_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e54e662",
   "metadata": {},
   "outputs": [],
   "source": [
    "step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db92e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf8da84",
   "metadata": {},
   "outputs": [],
   "source": [
    "lam_tar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c054911",
   "metadata": {},
   "outputs": [],
   "source": [
    "spk_tar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe962afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "lam_spk_tar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b96c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25936d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_item.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f16fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_item.edge_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2b7ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_item.y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7055e222",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fd85e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lam[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9428961e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
