{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2719f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03251229",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from easydict import EasyDict as edict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02ec51c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = glob('./config/GTS/*.yaml')[0]\n",
    "config = edict(yaml.load(open(config_file, 'r'), Loader=yaml.FullLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13e775b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lambda_raster(im_o, im_t):\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(90, 80))\n",
    "    time = im_o.shape[0] / 10000\n",
    "    extent = [0, time, 0, 100]\n",
    "    im_o = axes[0].imshow(np.transpose(im_o), cmap='binary', extent=extent)\n",
    "    im_t = axes[1].imshow(np.transpose(im_t), cmap='binary', extent=extent)\n",
    "    ylabel = 'Lambda'\n",
    "    axes[0].set_title('Prediction\\n', fontsize = 30)\n",
    "    axes[0].set_xlabel('Time(s)', fontsize = 30)\n",
    "    axes[0].set_ylabel('Node index', fontsize = 30)\n",
    "    axes[0].set_aspect(0.1)\n",
    "    axes[0].tick_params(axis='x', labelsize=20)\n",
    "    axes[0].tick_params(axis='y', labelsize=20)\n",
    "    axes[1].set_title('Target\\n', fontsize = 30)\n",
    "    axes[1].set_xlabel('Time(s)', fontsize = 30)\n",
    "    axes[1].set_ylabel('Node index', fontsize = 30)\n",
    "    axes[1].set_aspect(0.1)\n",
    "    axes[1].tick_params(axis='x', labelsize=20)\n",
    "    axes[1].tick_params(axis='y', labelsize=20)\n",
    "    cax_o = fig.add_axes([axes[0].get_position().x1+0.01,axes[0].get_position().y0,0.02,axes[0].get_position().height])\n",
    "    cax_t = fig.add_axes([axes[1].get_position().x1+0.01,axes[1].get_position().y0,0.02,axes[1].get_position().height])\n",
    "    cbar1 = plt.colorbar(im_o, cax=cax_o)\n",
    "    cbar2 = plt.colorbar(im_t, cax=cax_t)\n",
    "    cbar1.ax.set_ylabel(ylabel, fontsize=30)\n",
    "    cbar1.ax.tick_params(axis='y', labelsize=20)\n",
    "    cbar2.ax.set_ylabel(ylabel, fontsize=30)\n",
    "    cbar2.ax.tick_params(axis='y', labelsize=20)\n",
    "#     plt.savefig(‘./fig/lamall_RNN_{}.png’.format(suffix), bbox_inches=‘tight’)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b9408b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import build_fully_connected_edge_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "020c8617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a131f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike = pickle.load(open('./data/LNP_spk_all.pickle', 'rb'))\n",
    "lam = pickle.load(open('./data/LNP_lam_all.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1ec152e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data, Batch, Dataset, InMemoryDataset\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a76e90e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.torch_geometric_spike_dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bfa93ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.dataset.train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47668e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spike[:, :config.dataset.train_step]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcc1103f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 4000000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7046e6c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Train_Dataset(root=config.dataset.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c86e2a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Train_Dataset(39999)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6fde2b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "713dc682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[12800, 200], y=[12800, 20, 2], batch=[12800], ptr=[129])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a0a91cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "63\n"
     ]
    }
   ],
   "source": [
    "for data_batch in train_loader:\n",
    "    print(data_batch.x.shape[0]//100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9cdf3858",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = True\n",
    "device = 'gpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ecc196e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O\n"
     ]
    }
   ],
   "source": [
    "if (use_gpu) and (device != 'cpu'):\n",
    "    print(\"O\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8e268114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[6300, 200], y=[6300, 20, 2], batch=[6300], ptr=[64])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_batch.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "63bc46e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6300])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_batch.batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7d4179f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6300"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_batch.x.shape[0] / "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "68f4d825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300, 200])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_batch.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fc4029f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300, 20, 2])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_batch.y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ba970ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0157, 0.0159, 0.0160,  ..., 0.0165, 0.0167, 0.0168],\n",
       "        [0.0132, 0.0134, 0.0136,  ..., 0.0141, 0.0143, 0.0144],\n",
       "        [0.0097, 0.0100, 0.0102,  ..., 0.0107, 0.0109, 0.0111],\n",
       "        ...,\n",
       "        [0.0165, 0.0166, 0.0167,  ..., 0.0166, 0.0167, 0.0169],\n",
       "        [0.0174, 0.0175, 0.0177,  ..., 0.0178, 0.0179, 0.0181],\n",
       "        [0.0172, 0.0173, 0.0174,  ..., 0.0178, 0.0179, 0.0181]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_batch.y[:100,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "012bf389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_batch.y[:100,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6b15f493",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_batch.edge_index = new_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d693322e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,  ..., 299, 299, 299],\n",
       "        [  1,   2,   3,  ..., 296, 297, 298]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_batch.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "78c6418d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 29700])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_batch.edge_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "34c05cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_batch_edge_index(edge_index, num_graphs):\n",
    "    new_edge = edge_index\n",
    "    for num in range(1,num_graphs):\n",
    "        next_graph_edge = edge_index + num*100\n",
    "        new_edge = torch.cat([new_edge, next_graph_edge], dim=-1)\n",
    "    \n",
    "        \n",
    "    return new_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2602aa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = build_fully_connected_edge_idx(num_nodes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d397a6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_edge = build_batch_edge_index(edge_index, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3f1c6411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1267200])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_edge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4aece81e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,     0,     0,  ..., 12799, 12799, 12799],\n",
       "        [    1,     2,     3,  ..., 12796, 12797, 12798]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cdfa83e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  ..., 99, 99, 99],\n",
       "        [ 1,  2,  3,  ..., 96, 97, 98]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_edge[:,:9900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b7beda37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[100, 100, 100,  ..., 199, 199, 199],\n",
       "        [101, 102, 103,  ..., 196, 197, 198]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_edge[:,9900:9900*2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "295a9ffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[200, 200, 200,  ..., 299, 299, 299],\n",
       "        [201, 202, 203,  ..., 296, 297, 298]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_edge[:,9900*2:9900*3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "87fb91db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for num in range(1,3):\n",
    "    print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b361b803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29700"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9900*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fe316ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = glob('./data/spike_lambda/processed/train_n100.pt')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfa941da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data/spike_lambda/processed/train_n100.pt'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33e0f488",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.load(dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce40da1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(x=[81600000, 20], y=[81600000, 2, 2]),\n",
       " defaultdict(dict,\n",
       "             {'x': tensor([       0,  4800000,  9600000, 14400000, 19200000, 24000000, 28800000,\n",
       "                      33600000, 38400000, 43200000, 48000000, 52800000, 57600000, 62400000,\n",
       "                      67200000, 72000000, 76800000, 81600000]),\n",
       "              'y': tensor([       0,  4800000,  9600000, 14400000, 19200000, 24000000, 28800000,\n",
       "                      33600000, 38400000, 43200000, 48000000, 52800000, 57600000, 62400000,\n",
       "                      67200000, 72000000, 76800000, 81600000])}))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6876adb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
